{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853a7f87-9a03-41df-904a-ddc114f6fea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration_Seconds\n",
      "Estimated_Key\n",
      "Key_Confidence\n",
      "Average_Pitch\n",
      "Pitch_Std\n",
      "Pitch_Range\n",
      "pYIN_Mean_Pitch\n",
      "pYIN_Pitch_Std\n",
      "pYIN_Pitch_Range\n",
      "pYIN_Voiced_Rate\n",
      "pYIN_Mean_Confidence\n",
      "pYIN_Pitch_Stability\n",
      "pYIN_Pitch_Clarity\n",
      "Harmonic_Salience\n",
      "Tempo_BPM\n",
      "Beat_Regularity\n",
      "Beat_Density\n",
      "Beat_Strength\n",
      "Groove_Consistency\n",
      "Average_Spectral_Centroid\n",
      "Spectral_Centroid_Std\n",
      "Average_Spectral_Rolloff\n",
      "Spectral_Rolloff_Std\n",
      "Average_Spectral_Bandwidth\n",
      "Spectral_Bandwidth_Std\n",
      "Spectral_Contrast_Mean\n",
      "Spectral_Contrast_Std\n",
      "Spectral_Entropy\n",
      "Spectral_Flatness\n",
      "Tonnetz_1\n",
      "Tonnetz_2\n",
      "Tonnetz_3\n",
      "Tonnetz_4\n",
      "Tonnetz_5\n",
      "Tonnetz_6\n",
      "Poly_Coefficient_1\n",
      "Poly_Coefficient_2\n",
      "Poly_Coefficient_3\n",
      "Poly_Coefficient_4\n",
      "Poly_Coefficient_5\n",
      "RMS_Energy_Mean\n",
      "RMS_Energy_Std\n",
      "Dynamic_Range\n",
      "Crest_Factor\n",
      "PCEN_Energy_Mean\n",
      "PCEN_Energy_Std\n",
      "Harmonic_Energy\n",
      "Percussive_Energy\n",
      "Harmonic_Ratio\n",
      "Tonal_Energy_Ratio\n",
      "VQT_Mean\n",
      "VQT_Std\n",
      "bass_presence\n",
      "kick_drum_presence\n",
      "snare_presence\n",
      "cymbals_presence\n",
      "electric_guitar_presence\n",
      "vocals_presence\n",
      "synthesizer_presence\n",
      "guitar_distortion\n",
      "drum_prominence\n",
      "vocal_harmonicity\n",
      "rhythm_regularity\n",
      "rhythm_density\n",
      "drum_pattern_strength\n",
      "timbre_brightness\n",
      "timbre_complexity\n",
      "instrument_richness\n",
      "vocal_pitch_range\n",
      "vocal_pitch_stability\n",
      "vocal_vibrato\n",
      "vocal_formant_variation\n",
      "vocal_clarity\n",
      "Reassigned_Frequency_Mean\n",
      "Reassigned_Magnitude_Mean\n",
      "Chroma_Mean\n",
      "Chroma_Std\n",
      "Zero_Crossing_Rate_Mean\n",
      "Zero_Crossing_Rate_Std\n",
      "MFCC_1_Mean\n",
      "MFCC_1_Std\n",
      "MFCC_1_Delta_Mean\n",
      "MFCC_1_Delta_Std\n",
      "MFCC_1_Delta2_Mean\n",
      "MFCC_1_Delta2_Std\n",
      "MFCC_2_Mean\n",
      "MFCC_2_Std\n",
      "MFCC_2_Delta_Mean\n",
      "MFCC_2_Delta_Std\n",
      "MFCC_2_Delta2_Mean\n",
      "MFCC_2_Delta2_Std\n",
      "MFCC_3_Mean\n",
      "MFCC_3_Std\n",
      "MFCC_3_Delta_Mean\n",
      "MFCC_3_Delta_Std\n",
      "MFCC_3_Delta2_Mean\n",
      "MFCC_3_Delta2_Std\n",
      "MFCC_4_Mean\n",
      "MFCC_4_Std\n",
      "MFCC_4_Delta_Mean\n",
      "MFCC_4_Delta_Std\n",
      "MFCC_4_Delta2_Mean\n",
      "MFCC_4_Delta2_Std\n",
      "MFCC_5_Mean\n",
      "MFCC_5_Std\n",
      "MFCC_5_Delta_Mean\n",
      "MFCC_5_Delta_Std\n",
      "MFCC_5_Delta2_Mean\n",
      "MFCC_5_Delta2_Std\n",
      "MFCC_6_Mean\n",
      "MFCC_6_Std\n",
      "MFCC_6_Delta_Mean\n",
      "MFCC_6_Delta_Std\n",
      "MFCC_6_Delta2_Mean\n",
      "MFCC_6_Delta2_Std\n",
      "MFCC_7_Mean\n",
      "MFCC_7_Std\n",
      "MFCC_7_Delta_Mean\n",
      "MFCC_7_Delta_Std\n",
      "MFCC_7_Delta2_Mean\n",
      "MFCC_7_Delta2_Std\n",
      "MFCC_8_Mean\n",
      "MFCC_8_Std\n",
      "MFCC_8_Delta_Mean\n",
      "MFCC_8_Delta_Std\n",
      "MFCC_8_Delta2_Mean\n",
      "MFCC_8_Delta2_Std\n",
      "MFCC_9_Mean\n",
      "MFCC_9_Std\n",
      "MFCC_9_Delta_Mean\n",
      "MFCC_9_Delta_Std\n",
      "MFCC_9_Delta2_Mean\n",
      "MFCC_9_Delta2_Std\n",
      "MFCC_10_Mean\n",
      "MFCC_10_Std\n",
      "MFCC_10_Delta_Mean\n",
      "MFCC_10_Delta_Std\n",
      "MFCC_10_Delta2_Mean\n",
      "MFCC_10_Delta2_Std\n",
      "MFCC_11_Mean\n",
      "MFCC_11_Std\n",
      "MFCC_11_Delta_Mean\n",
      "MFCC_11_Delta_Std\n",
      "MFCC_11_Delta2_Mean\n",
      "MFCC_11_Delta2_Std\n",
      "MFCC_12_Mean\n",
      "MFCC_12_Std\n",
      "MFCC_12_Delta_Mean\n",
      "MFCC_12_Delta_Std\n",
      "MFCC_12_Delta2_Mean\n",
      "MFCC_12_Delta2_Std\n",
      "MFCC_13_Mean\n",
      "MFCC_13_Std\n",
      "MFCC_13_Delta_Mean\n",
      "MFCC_13_Delta_Std\n",
      "MFCC_13_Delta2_Mean\n",
      "MFCC_13_Delta2_Std\n",
      "Onset_Rate\n",
      "Onset_Strength_Mean\n",
      "Onset_Strength_Std\n",
      "Tempogram_Mean\n",
      "Tempogram_Std\n",
      "Tempogram_Ratio\n",
      "Pulse_Clarity\n",
      "HPSS_Harmonic_Mean\n",
      "HPSS_Percussive_Mean\n",
      "HPSS_Ratio\n",
      "Segment_Count\n",
      "Average_Segment_Duration\n",
      "Segment_Duration_Std\n",
      "First_Segment_Time\n",
      "Last_Segment_Time\n",
      "Bass_Prominence\n",
      "Vocal_Presence\n",
      "Emotional_Valence\n",
      "Emotional_Arousal\n",
      "Sample_Rate\n",
      "RQA_Density\n",
      "RQA_Hist_Bin_1\n",
      "RQA_Hist_Bin_2\n",
      "RQA_Hist_Bin_3\n",
      "RQA_Hist_Bin_4\n",
      "RQA_Hist_Bin_5\n",
      "RQA_Hist_Bin_6\n",
      "RQA_Hist_Bin_7\n",
      "RQA_Hist_Bin_8\n",
      "RQA_Hist_Bin_9\n",
      "RQA_Hist_Bin_10\n",
      "Path_Structure_Mean\n",
      "Path_Structure_Std\n",
      "Estimated_Key_Numeric\n",
      "Saved ordered song IDs with values to ordered_songs_by_feature_with_values.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def key_to_number(key_str):\n",
    "    \"\"\"Convert key strings to numerical values.\n",
    "    Major keys: C=0, C#=1, D=2, ... B=11\n",
    "    Minor keys: Am=12, A#m=13, Bm=14, ... G#m=23\n",
    "    \n",
    "    Handles various notations:\n",
    "    - Full notation: 'C major', 'D minor'\n",
    "    - Short notation: 'C', 'Dm'\n",
    "    - Symbol notation: 'C#', 'F#m'\n",
    "    \"\"\"\n",
    "    if pd.isna(key_str) or key_str == '':\n",
    "        return np.nan\n",
    "    \n",
    "    # Standardize the key string (replace flats with equivalent sharps)\n",
    "    key_str = key_str.replace('Ab', 'G#').replace('Bb', 'A#').replace('Cb', 'B').replace('Db', 'C#').replace('Eb', 'D#')\n",
    "    key_str = key_str.strip()\n",
    "    \n",
    "    # Define all possible notes\n",
    "    notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    \n",
    "    # Case 1: Full notation (e.g., \"C major\", \"D minor\")\n",
    "    full_notation = re.match(r'([A-G][#]?)\\s*(major|minor)$', key_str)\n",
    "    if full_notation:\n",
    "        note, scale = full_notation.groups()\n",
    "        note_idx = notes.index(note) if note in notes else -1\n",
    "        if note_idx >= 0:\n",
    "            if scale == 'major':\n",
    "                return note_idx\n",
    "            else:  # minor\n",
    "                return note_idx + 3 + 12  # Relative minor is 3 semitones up, then add 12 to differentiate\n",
    "    \n",
    "    # Case 2: Short notation with explicit minor (e.g., \"Dm\", \"F#m\")\n",
    "    short_minor = re.match(r'([A-G][#]?)m$', key_str)\n",
    "    if short_minor:\n",
    "        note = short_minor.group(1)\n",
    "        note_idx = notes.index(note) if note in notes else -1\n",
    "        if note_idx >= 0:\n",
    "            return note_idx + 3 + 12  # Minor key\n",
    "    \n",
    "    # Case 3: Just the note name - assume major (e.g., \"C\", \"F#\")\n",
    "    if key_str in notes:\n",
    "        return notes.index(key_str)  # Major key\n",
    "    \n",
    "    print(f\"Could not parse key: {key_str}\")\n",
    "    return np.nan\n",
    "\n",
    "def main():\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\Cheig\\\\OneDrive\\\\Desktop\\\\csvs\\\\data_with_ids.csv\")  # Replace with your actual file name\n",
    "    \n",
    "    # Convert Estimated_Key to numerical values\n",
    "    df['Estimated_Key_Numeric'] = df['Estimated_Key'].apply(key_to_number)\n",
    "    \n",
    "    # Identify columns to process (exclude song_id, Title, Artist, Album)\n",
    "    exclude_cols = ['song_id', 'Title', 'Artist', 'Album']\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    # Create a dictionary to store ordered song IDs and their values for each feature\n",
    "    ordered_songs_dict = {}\n",
    "    \n",
    "    # For each feature, sort songs and extract ordered list of song_ids with values\n",
    "    for feature in feature_cols:\n",
    "        # Skip if the feature is non-numeric\n",
    "        if df[feature].dtype == 'object' and feature != 'Estimated_Key':\n",
    "            print(f\"Skipping non-numeric feature: {feature}\")\n",
    "            continue\n",
    "        \n",
    "        # Use the numeric version for Estimated_Key for sorting, but preserve the original key name in output\n",
    "        if feature == 'Estimated_Key':\n",
    "            sort_feature = 'Estimated_Key_Numeric'\n",
    "            feature_to_store = 'Estimated_Key'\n",
    "        else:\n",
    "            sort_feature = feature\n",
    "            feature_to_store = feature\n",
    "        \n",
    "        # Sort by feature value and extract song_ids with their values\n",
    "        try:\n",
    "            # Drop NaN values before sorting\n",
    "            sorted_df = df.dropna(subset=[sort_feature]).sort_values(by=sort_feature)\n",
    "            \n",
    "            # Create list of tuples (song_id, feature_value)\n",
    "            if feature == 'Estimated_Key':\n",
    "                # For Estimated_Key, store both original key and numeric value\n",
    "                ordered_songs_with_values = [\n",
    "                    (row['song_id'], (row[feature_to_store], row[sort_feature])) \n",
    "                    for _, row in sorted_df.iterrows()\n",
    "                ]\n",
    "            else:\n",
    "                ordered_songs_with_values = [\n",
    "                    (row['song_id'], row[feature_to_store]) \n",
    "                    for _, row in sorted_df.iterrows()\n",
    "                ]\n",
    "            \n",
    "            # Store in dictionary\n",
    "            ordered_songs_dict[feature_to_store] = ordered_songs_with_values\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing feature {feature}: {e}\")\n",
    "        print(feature)\n",
    "    # Create a new DataFrame for the ordered song IDs with values\n",
    "    result_df = pd.DataFrame({\n",
    "        'feature': list(ordered_songs_dict.keys()),\n",
    "        'ordered_song_ids_with_values': list(ordered_songs_dict.values())\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    result_df.to_csv('ordered_songs_by_feature_with_values.csv', index=False)\n",
    "    print(f\"Saved ordered song IDs with values to ordered_songs_by_feature_with_values.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6203bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def load_data1(csv_filename):\n",
    "    \"\"\"Load the CSV and parse the ordered song IDs as lists using pandas.\"\"\"\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    data = {row[\"feature\"]: ast.literal_eval(row[\"ordered_song_ids\"]) for _, row in df.iterrows()}\n",
    "    return data\n",
    "def load_data2(csv_filename):\n",
    "    \"\"\"Load the CSV and parse the ordered song IDs with values using pandas.\"\"\"\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    data = {row[\"feature\"]: ast.literal_eval(row[\"ordered_song_ids_with_values\"]) for _, row in df.iterrows()}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f020e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = load_data1(\"C:\\\\Users\\\\Cheig\\\\capstone\\\\ordered_songs_by_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca9966e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common nearby song: [(39618, 173), (39542, 86), (30191, 18), (37540, 17), (38588, 17), (26109, 17), (5616, 17), (36754, 16), (12725, 16), (5379, 16)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def load_data(csv_filename):\n",
    "    \"\"\"Load the CSV and parse the ordered song IDs as lists using pandas.\"\"\"\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    data = {row[\"feature\"]: ast.literal_eval(row[\"ordered_song_ids\"]) for _, row in df.iterrows()}\n",
    "    return data\n",
    "\n",
    "def find_nearest_songs(data, song_id, num_neighbors=1000):\n",
    "    \"\"\"Find the 100 nearest songs for each feature and count occurrences.\"\"\"\n",
    "    song_counts = Counter()\n",
    "    \n",
    "    for feature, song_list in data.items():\n",
    "        if song_id in song_list:\n",
    "            index = song_list.index(song_id)\n",
    "            nearest_songs = song_list[max(0, index - num_neighbors // 2): index + num_neighbors // 2]\n",
    "            song_counts.update(nearest_songs)\n",
    "    \n",
    "    # Remove the original song ID itself from the count\n",
    "    song_counts.pop(song_id, None)\n",
    "    \n",
    "    # Find the most common nearby song\n",
    "    most_common_song = song_counts.most_common(10) if song_counts else (None, 0)\n",
    "    \n",
    "    return most_common_song\n",
    "\n",
    "# Example usage\n",
    "csv_filename = \"C:\\\\Users\\\\Cheig\\\\capstone\\\\ordered_songs_by_feature.csv\"  # Change this to your actual CSV filename\n",
    "song_id_to_search = 30199  # Change this to the song ID you're searching for\n",
    "\n",
    "data = data1\n",
    "most_common_song = find_nearest_songs(data, song_id_to_search)\n",
    "print(f\"Most common nearby song: {most_common_song}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa034744",
   "metadata": {},
   "source": [
    "[(39618, 172), (39542, 13), (19891, 6), (47258, 5), (29598, 5), (4185, 5), (4190, 5), (42534, 5), (21070, 5), (43723, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05f7a2e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m csv_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCheig\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcapstone\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mordered_songs_by_feature_with_values.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this to your actual CSV filename\u001b[39;00m\n\u001b[0;32m     35\u001b[0m song_id_to_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Change this to the song ID you're searching for\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m data \u001b[38;5;241m=\u001b[39m load_data(csv_filename)\n\u001b[0;32m     38\u001b[0m most_common_song \u001b[38;5;241m=\u001b[39m find_nearest_songs(data, song_id_to_search)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMost common nearby song: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmost_common_song\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(csv_filename)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the CSV and parse the ordered song IDs with values using pandas.\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_filename)\n\u001b[1;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m {row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ast\u001b[38;5;241m.\u001b[39mliteral_eval(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mordered_song_ids_with_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows()}\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Cheig\\anaconda3\\Lib\\ast.py:112\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[1;32mc:\\Users\\Cheig\\anaconda3\\Lib\\ast.py:86\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_num(node)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert\u001b[39m(node):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant):\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import bisect\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def find_nearest_songs(data, song_id, num_neighbors=100):\n",
    "    \"\"\"Find the 100 nearest songs using binary search based on values.\"\"\"\n",
    "    song_counts = Counter()\n",
    "    \n",
    "    for feature, song_list in data.items():\n",
    "        song_ids = [song[0] for song in song_list]  # Extract song IDs\n",
    "        values = [song[1] for song in song_list]  # Extract values\n",
    "        \n",
    "        index = bisect.bisect_left(song_ids, song_id)  # Find position using binary search\n",
    "        if index < len(song_ids) and song_ids[index] == song_id:\n",
    "            nearest_songs = song_ids[max(0, index - num_neighbors // 2): index + num_neighbors // 2]\n",
    "            song_counts.update(nearest_songs)\n",
    "    \n",
    "    # Remove the original song ID itself from the count\n",
    "    song_counts.pop(song_id, None)\n",
    "    \n",
    "    # Find the most common nearby song\n",
    "    most_common_song= song_counts.most_common(10) if song_counts else (None, 0)\n",
    "    \n",
    "    return most_common_song,\n",
    "\n",
    "# Example usage\n",
    "csv_filename = \"C:\\\\Users\\\\Cheig\\\\capstone\\\\ordered_songs_by_feature_with_values.csv\"  # Change this to your actual CSV filename\n",
    "song_id_to_search = 1  # Change this to the song ID you're searching for\n",
    "\n",
    "data = load_data(csv_filename)\n",
    "most_common_song = find_nearest_songs(data, song_id_to_search)\n",
    "print(f\"Most common nearby song: {most_common_song}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2397b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "distance_matrix = pd.read_csv(\"distances2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47384a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('90', 5.795593522907614), ('75', 6.005682414950607), ('24497', 6.02461700560429), ('189', 6.239342590205207), ('45212', 6.313814136778167), ('15733', 6.330860637777792), ('98', 6.393084541841931), ('45255', 6.451410435094632), ('107', 6.464909964167343), ('25828', 6.487933809127037)]\n",
      "Top 10 songs most similar to 100:\n",
      "1. Song ID: 90, Distance: 5.7956\n",
      "2. Song ID: 75, Distance: 6.0057\n",
      "3. Song ID: 24497, Distance: 6.0246\n",
      "4. Song ID: 189, Distance: 6.2393\n",
      "5. Song ID: 45212, Distance: 6.3138\n",
      "6. Song ID: 15733, Distance: 6.3309\n",
      "7. Song ID: 98, Distance: 6.3931\n",
      "8. Song ID: 45255, Distance: 6.4514\n",
      "9. Song ID: 107, Distance: 6.4649\n",
      "10. Song ID: 25828, Distance: 6.4879\n"
     ]
    }
   ],
   "source": [
    "def find_similar_songs(song_id, n=10):\n",
    "    \"\"\"\n",
    "    Find the n most similar songs to the given song_id.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file (str): Path to the CSV file containing the distance matrix\n",
    "    song_id (str): ID of the song to find similar songs for\n",
    "    n (int): Number of similar songs to return (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "    list: List of tuples (song_id, distance) for the n most similar songs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the song_id exists in the dataset\n",
    "    if song_id not in distance_matrix.index:\n",
    "        return f\"Song ID '{song_id}' not found in the dataset.\"\n",
    "    \n",
    "    # Get the row for the specified song_id\n",
    "    distances = distance_matrix.loc[song_id]\n",
    "    \n",
    "    # Sort the distances in ascending order (closest first)\n",
    "    # Exclude the song itself (distance = 0)\n",
    "    sorted_distances = distances.sort_values()\n",
    "    \n",
    "    # Remove the song itself (will be at index 0 with distance 0)\n",
    "    if sorted_distances.index[0] == song_id or sorted_distances.iloc[0] == 0:\n",
    "        sorted_distances = sorted_distances.iloc[1:]\n",
    "    \n",
    "    # Return the top n similar songs with their distances\n",
    "    similar_songs = [(idx, dist) for idx, dist in \n",
    "                     zip(sorted_distances.index[:n], sorted_distances.values[:n])]\n",
    "    \n",
    "    return similar_songs\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual CSV file path and song ID\n",
    "    song_id = 100  # Replace with your actual song ID\n",
    "    \n",
    "    similar_songs = find_similar_songs(song_id)\n",
    "    print(similar_songs)\n",
    "    print(f\"Top 10 songs most similar to {song_id}:\")\n",
    "    for i, (similar_id, distance) in enumerate(similar_songs, 1):\n",
    "        print(f\"{i}. Song ID: {similar_id}, Distance: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ceab97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea854f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd489bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11222,TE MATA,Feid,INTER SHIBUYA (FERXXO EDITION),113.12,C major,0.6812122948850745,1328.3975830078125,966.456787109375,3853.69873046875,138.19027210595792,84.46632711250275,553.263656988684,0.5814168377823409,0.1727958024910659,0.0518779902587347,5.78714412294581,0.1166161075234413,112.34714673913044,18.640080416880373,1.60007072135785,1.4009597301483154,27.36082000793177,3485.3446391149887,1872.8492680223808,7551.129045157597,4018.727730383597,3637.869828118626,1465.2302040459315,22.47957206700756,14.476959087449586,1.0,0.0038064462132751,0.0933149676440971,0.0302356409083095,0.0056167947021982,0.0567645261216662,0.0015421378393131,-0.0016682281797917,2.1284595522415648e-10,-4.88952000080811e-07,0.0003821593249041,-0.118290635394755,13.021915441176535,0.2083112150430679,0.1574039012193679,0.7005082368850708,3.829923152923584,0.2144597433609426,0.3889042381110932,0.1166161075234413,0.0660918429493904,1.4765149354934692,0.463833212852478,0.7566723227500916,1.87850284576416,15.738718032836914,28.63440704345703,7.955277919769287,0.8048398494720459,2.2703897953033447,2.6151180267333984,1.878843903541565,0.0006711782189086,0.3909777402877807,1.7644551992416382,6.8597586647288304,3.6686704384724185,8.972517013549805,7.954811573028564,66.10935974121094,23.62055065639309,3853.69873046875,0.0010338589781895,6.771565437316895,4018.727730383597,17.8016482388115,3936.635731234289,1.5903602838516235,0.4528567194938659,0.315658688545227,0.0675575494374743,0.0593171708374753,-152.3648223876953,124.03955841064452,0.0017667779466137,17.171310424804688,-0.000136573522468,8.601082801818848,101.00070190429688,40.35942459106445,0.0023829315323382,6.331023216247559,-0.0001801710459403,3.1233832836151123,-2.255601644515991,27.75527000427246,0.0020694143604487,3.9666152000427246,-0.0001490545837441,2.1406805515289307,18.772838592529297,39.32360076904297,0.0016439517494291,3.7890758514404297,-0.0001191088958876,1.7728251218795776,-22.29355239868164,20.417707443237305,0.0012080881278961,2.93129825592041,-0.0001107057905755,1.4450770616531372,16.74798583984375,25.60814094543457,0.0008391875890083,3.258012294769287,-0.0001337691501248,1.4639378786087036,-14.075129508972168,16.931488037109375,0.0005668885423801,2.519221305847168,-0.0001810444664442,1.2747445106506348,6.0478339195251465,19.586584091186523,0.0003759019309654,2.070576906204224,-0.0002298439067089,1.051316499710083,-7.116996765136719,15.292885780334473,0.0002303831133758,2.0137338638305664,-0.0002517513639759,1.0083341598510742,7.007184028625488,15.796504974365234,0.0001040072675095,1.9249494075775144,-0.0002258046297356,0.9648210406303406,-5.912801742553711,13.425474166870115,-2.128345840901602e-06,1.938229322433472,-0.0001486489200033,0.9938627481460572,3.2243220806121826,14.443333625793455,-6.320431566564366e-05,1.7277512550354004,-3.656218905234709e-05,0.8730620741844177,-5.689050197601318,12.44824504852295,-5.204121771384962e-05,1.8441452980041504,8.17062464193441e-05,0.9208766222000122,3.6686704384724185,1.4009597301483154,2.571836233139038,23.823392868041992,29.28634262084961,10.129961234738564,0.1383101940155029,0.1166161075234413,0.0660918429493904,1.7644553184509275,415.0,0.2668892613406071,0.1457777132225021,0.4760090702947845,110.96816326530612,14.530141830444336,0.3754023015499115,0.3911081658652714,0.8046354651451111,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "def find_song_by_id(csv_file, song_id):\n",
    "    try:\n",
    "        with open(csv_file, 'r') as file:\n",
    "            for line in file:\n",
    "                if line.startswith(str(song_id) + \",\"):\n",
    "                    print(line.strip())\n",
    "                    return\n",
    "        print(f\"No song found with song_id: {song_id}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    find_song_by_id(\"C:\\\\Users\\\\Cheig\\\\OneDrive\\\\Desktop\\\\csvs\\\\data_with_ids.csv\", 11222)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2604946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeeee\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m row_to_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 31\u001b[0m data \u001b[38;5;241m=\u001b[39m read_specific_row(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistances2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m11111\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_to_read\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mread_specific_row\u001b[1;34m(filename, row_number)\u001b[0m\n\u001b[0;32m     17\u001b[0m reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(file)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeeee\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(reader)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeeee\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m row_number \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(rows):\n",
      "File \u001b[1;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_specific_row(filename, row_number):\n",
    "    \"\"\"Reads a specific row from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the CSV file.\n",
    "        row_number (int): The row number to read (starting from 0).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings representing the row, or None if the row \n",
    "              number is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            \n",
    "            reader = csv.reader(file)\n",
    "            print(\"eeeee\")\n",
    "            rows = list(reader)\n",
    "            print(\"eeeee\")\n",
    "            if 0 <= row_number < len(rows):\n",
    "                return rows[row_number]\n",
    "            else:\n",
    "                return None\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "    \n",
    "# Example usage\n",
    "filename = 'my_data.csv'\n",
    "row_to_read = 2\n",
    "data = read_specific_row(\"distances2.csv\", 11111)\n",
    "\n",
    "if data:\n",
    "    print(f\"Row {row_to_read}: {data}\")\n",
    "else:\n",
    "    print(f\"Row {row_to_read} not found or file does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bdceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
